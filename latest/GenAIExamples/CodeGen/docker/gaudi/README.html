<!DOCTYPE html>
<html class="writer-html5" lang="en" data-content_root="../../../../">
<head>
  <meta charset="utf-8" /><meta name="viewport" content="width=device-width, initial-scale=1" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Build MegaService of CodeGen on Gaudi &mdash; OPEA™ 0.7 documentation</title>
      <link rel="stylesheet" type="text/css" href="../../../../_static/pygments.css?v=fa44fd50" />
      <link rel="stylesheet" type="text/css" href="../../../../_static/css/theme.css?v=19f00094" />
      <link rel="stylesheet" type="text/css" href="../../../../_static/graphviz.css?v=fd3f3429" />
      <link rel="stylesheet" type="text/css" href="../../../../_static/opea-custom.css?v=4df7fe99" />
      <link rel="stylesheet" type="text/css" href="../../../../_static/tabs.css?v=a5c4661c" />

  
    <link rel="shortcut icon" href="../../../../_static/OPEA-favicon-32x32.png"/>
  <!--[if lt IE 9]>
    <script src="../../../../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script src="../../../../_static/jquery.js?v=5d32c60e"></script>
        <script src="../../../../_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
        <script src="../../../../_static/documentation_options.js?v=48f8e935"></script>
        <script src="../../../../_static/doctools.js?v=9a2dae69"></script>
        <script src="../../../../_static/sphinx_highlight.js?v=dc90522c"></script>
        <script src="../../../../_static/opea-custom.js?v=22d49862"></script>
    <script src="../../../../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../../../../genindex.html" />
    <link rel="search" title="Search" href="../../../../search.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="../../../../index.html" class="icon icon-home">
            OPEA™
              <img src="../../../../_static/opea-horizontal-white-w200.png" class="logo" alt="Logo"/>
          </a>
              <div class="version">
                latest
              </div>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
  
  <div class="rst-versions" data-toggle="rst-versions" role="note" aria-label="versions">
    <span class="rst-current-version" data-toggle="rst-current-version">
      <span class="fa fa-book"> OPEA Project</span>
      v: latest
      <span class="fa fa-caret-down"></span>
    </span>
    <div class="rst-other-versions">
      <dl>
        <dt>Document Versions</dt>
        
          <dd><a href="/latest/">latest</a></dd>
        
      </dl>
      <dl>
        <dt>OPEA Project links</dt>
          <dd>
            <a href="https://opea.dev">Project Home</a>
          </dd>
          <dd>
            <a href="https://github.com/opea-project/docs/wiki">Wiki</a>
          </dd>
      </dl>
    </div>
  </div>
  
              <ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../index.html">Documentation Home</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../guide.html">Installation Guides</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../../guide/installation/gmc_install/gmc_install.html">GenAI-microservices-connector(GMC) Installation</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../../guide/installation/gmc_install/gmc_install.html#genai-microservices-connector-gmc">GenAI-microservices-connector(GMC)</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../guide/installation/gmc_install/gmc_install.html#install-gmc">Install GMC</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../guide/installation/gmc_install/gmc_install.html#use-gmc-to-compose-a-chatqna-pipeline">Use GMC to compose a chatQnA Pipeline</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../../guide/installation/k8s_install/k8s_instal_aws_eks.html">Kubernetes Installation using AWS EKS Cluster</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../../guide/installation/k8s_install/k8s_instal_aws_eks.html#prerequisites">Prerequisites</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../guide/installation/k8s_install/k8s_instal_aws_eks.html#create-aws-eks-cluster-in-aws-console">Create AWS EKS Cluster in AWS Console</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../guide/installation/k8s_install/k8s_instal_aws_eks.html#uploading-images-to-an-aws-private-registry">Uploading images to an AWS Private Registry</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../../guide/installation/k8s_install/k8s_install_kubeadm.html">Kubernetes installation demo using kubeadm</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../../guide/installation/k8s_install/k8s_install_kubeadm.html#node-configuration">Node configuration</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../guide/installation/k8s_install/k8s_install_kubeadm.html#step-0-clean-up-the-environment">Step 0. Clean up the environment</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../guide/installation/k8s_install/k8s_install_kubeadm.html#step-1-install-relevant-components">Step 1. Install relevant components</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../guide/installation/k8s_install/k8s_install_kubeadm.html#step-2-create-the-k8s-cluster">Step 2. Create the k8s cluster</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../guide/installation/k8s_install/k8s_install_kubeadm.html#step-3-optional-reset-kubernetes-cluster">Step 3 (optional) Reset Kubernetes cluster</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../guide/installation/k8s_install/k8s_install_kubeadm.html#notes">NOTES</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../../guide/installation/k8s_install/k8s_install_kubespray.html">Kubernetes installation using Kubespray</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../../guide/installation/k8s_install/k8s_install_kubespray.html#node-preparation">Node preparation</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../guide/installation/k8s_install/k8s_install_kubespray.html#prerequisites">Prerequisites</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../guide/installation/k8s_install/k8s_install_kubespray.html#step-1-set-up-kubespray-and-ansible">Step 1. Set up Kubespray and Ansible</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../guide/installation/k8s_install/k8s_install_kubespray.html#step-2-build-your-own-inventory">Step 2. Build your own inventory</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../guide/installation/k8s_install/k8s_install_kubespray.html#step-3-deploy-kubernetes">Step 3. Deploy Kubernetes</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../guide/installation/k8s_install/k8s_install_kubespray.html#step-4-create-kubectl-configuration">Step 4. Create kubectl configuration</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../guide/installation/k8s_install/k8s_install_kubespray.html#quick-reference">Quick reference</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../../guide/installation/k8s_install/k8s_install_kubespray.html#how-to-deploy-a-single-node-kubernetes">How to deploy a single node Kubernetes?</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../guide/installation/k8s_install/k8s_install_kubespray.html#how-to-scale-kubernetes-cluster-to-add-more-nodes">How to scale Kubernetes cluster to add more nodes?</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../guide/installation/k8s_install/k8s_install_kubespray.html#how-to-config-proxy">How to config proxy?</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../../../community.html">Community</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../../rfcs.html">Request for Comments (RFCs)</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../../community/rfcs/README.html">RFC Archive</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../community/rfcs/24-05-16-GenAIExamples-001-Using_MicroService_to_implement_ChatQnA.html">RFC 24-05-15-GenAIExamples-001: Using MicroService to Implement ChatQnA</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../../community/rfcs/24-05-16-GenAIExamples-001-Using_MicroService_to_implement_ChatQnA.html#author">Author</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../community/rfcs/24-05-16-GenAIExamples-001-Using_MicroService_to_implement_ChatQnA.html#status">Status</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../community/rfcs/24-05-16-GenAIExamples-001-Using_MicroService_to_implement_ChatQnA.html#objective">Objective</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../community/rfcs/24-05-16-GenAIExamples-001-Using_MicroService_to_implement_ChatQnA.html#motivation">Motivation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../community/rfcs/24-05-16-GenAIExamples-001-Using_MicroService_to_implement_ChatQnA.html#design-proposal">Design Proposal</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../community/rfcs/24-05-16-GenAIExamples-001-Using_MicroService_to_implement_ChatQnA.html#alternatives-considered">Alternatives Considered</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../community/rfcs/24-05-16-GenAIExamples-001-Using_MicroService_to_implement_ChatQnA.html#compatibility">Compatibility</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../community/rfcs/24-05-16-GenAIExamples-001-Using_MicroService_to_implement_ChatQnA.html#miscs">Miscs</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../../community/rfcs/24-05-16-OPEA-001-Overall-Design.html">RFC 24-05-16-OPEA-001: Overall Design</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../../community/rfcs/24-05-16-OPEA-001-Overall-Design.html#author">Author</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../community/rfcs/24-05-16-OPEA-001-Overall-Design.html#status">Status</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../community/rfcs/24-05-16-OPEA-001-Overall-Design.html#objective">Objective</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../community/rfcs/24-05-16-OPEA-001-Overall-Design.html#motivation">Motivation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../community/rfcs/24-05-16-OPEA-001-Overall-Design.html#design-proposal">Design Proposal</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../community/rfcs/24-05-16-OPEA-001-Overall-Design.html#alternatives-considered">Alternatives Considered</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../community/rfcs/24-05-16-OPEA-001-Overall-Design.html#compatibility">Compatibility</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../community/rfcs/24-05-16-OPEA-001-Overall-Design.html#miscs">Miscs</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../../community/rfcs/24-05-24-OPEA-001-Code-Structure.html">RFC 24-05-24-OPEA-001: Code Structure</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../../community/rfcs/24-05-24-OPEA-001-Code-Structure.html#author">Author</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../community/rfcs/24-05-24-OPEA-001-Code-Structure.html#status">Status</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../community/rfcs/24-05-24-OPEA-001-Code-Structure.html#objective">Objective</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../community/rfcs/24-05-24-OPEA-001-Code-Structure.html#motivation">Motivation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../community/rfcs/24-05-24-OPEA-001-Code-Structure.html#design-proposal">Design Proposal</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../community/rfcs/24-05-24-OPEA-001-Code-Structure.html#miscs">Miscs</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../../community/CODE_OF_CONDUCT.html">Contributor Covenant Code of Conduct</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../../community/CODE_OF_CONDUCT.html#our-pledge">Our Pledge</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../community/CODE_OF_CONDUCT.html#our-standards">Our Standards</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../community/CODE_OF_CONDUCT.html#enforcement-responsibilities">Enforcement Responsibilities</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../community/CODE_OF_CONDUCT.html#scope">Scope</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../community/CODE_OF_CONDUCT.html#enforcement">Enforcement</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../community/CODE_OF_CONDUCT.html#enforcement-guidelines">Enforcement Guidelines</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../../community/CODE_OF_CONDUCT.html#correction">1. Correction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../community/CODE_OF_CONDUCT.html#warning">2. Warning</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../community/CODE_OF_CONDUCT.html#temporary-ban">3. Temporary Ban</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../community/CODE_OF_CONDUCT.html#permanent-ban">4. Permanent Ban</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../../community/CODE_OF_CONDUCT.html#attribution">Attribution</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../../community/CONTRIBUTING.html">Contribution Guidelines</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../../community/CONTRIBUTING.html#table-of-contents">Table of Contents</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../community/CONTRIBUTING.html#all-the-ways-to-contribute">All The Ways To Contribute</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../../community/CONTRIBUTING.html#community-discussions">Community Discussions</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../community/CONTRIBUTING.html#documentations">Documentations</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../community/CONTRIBUTING.html#reporting-issues">Reporting Issues</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../community/CONTRIBUTING.html#proposing-new-features">Proposing New Features</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../community/CONTRIBUTING.html#submitting-pull-requests">Submitting Pull Requests</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../../community/CONTRIBUTING.html#support">Support</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../community/CONTRIBUTING.html#contributor-covenant-code-of-conduct">Contributor Covenant Code of Conduct</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../../community/SECURITY.html">Reporting a Vulnerability</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../../community/SECURITY.html#script-usage-notice">Script Usage Notice</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../../community/pull_request_template.html">OPEA Pull Request Template</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../../community/pull_request_template.html#description">Description</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../community/pull_request_template.html#issues">Issues</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../community/pull_request_template.html#type-of-change">Type of change</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../community/pull_request_template.html#dependencies">Dependencies</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../community/pull_request_template.html#tests">Tests</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../../community/rfc_template.html">RFC Template</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../../community/rfc_template.html#rfc-title">RFC Title</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../community/rfc_template.html#rfc-content">RFC Content</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../../community/rfc_template.html#author">Author</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../community/rfc_template.html#status">Status</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../community/rfc_template.html#objective">Objective</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../community/rfc_template.html#motivation">Motivation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../community/rfc_template.html#design-proposal">Design Proposal</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../community/rfc_template.html#alternatives-considered">Alternatives Considered</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../community/rfc_template.html#compatibility">Compatibility</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../community/rfc_template.html#miscs">Miscs</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../../../release_notes.html">Release Notes</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../../release_notes/v0.7.html">OPEA Release Notes v0.7</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../../release_notes/v0.7.html#opea-highlights">OPEA Highlights</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../release_notes/v0.7.html#genaiexamples">GenAIExamples</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../release_notes/v0.7.html#genaicomps">GenAIComps</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../release_notes/v0.7.html#genaievals">GenAIEvals</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../release_notes/v0.7.html#genaiinfra">GenAIInfra</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../../release_notes/v0.6.html">OPEA Release Notes v0.06</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../../release_notes/v0.6.html#opea-highlight">OPEA Highlight</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../release_notes/v0.6.html#genaiexamples">GenAIExamples</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../release_notes/v0.6.html#genaicomps">GenAIComps</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../release_notes/v0.6.html#genaievals">GenAIEvals</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../release_notes/v0.6.html#genaiinfra">GenAIInfra</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../../../GenAIComps.html">Generative AI Components</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../../GenAIComps/README.html">Generative AI Components (GenAIComps)</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../../GenAIComps/README.html#genaicomps">GenAIComps</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../../GenAIComps/README.html#installation">Installation</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../../GenAIComps/README.html#microservice">MicroService</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../GenAIComps/README.html#megaservice">MegaService</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../GenAIComps/README.html#gateway">Gateway</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../GenAIComps/README.html#additional-content">Additional Content</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../../GenAIComps/LEGAL_INFORMATION.html">Legal Information</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../../GenAIComps/LEGAL_INFORMATION.html#license">License</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../GenAIComps/LEGAL_INFORMATION.html#citation">Citation</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../../GenAIComps/comps/asr/README.html">ASR Microservice</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../GenAIComps/comps/asr/README.html#start-microservice-with-python-option-1">🚀1. Start Microservice with Python (Option 1)</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../../GenAIComps/comps/asr/README.html#install-requirements">1.1 Install Requirements</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../GenAIComps/comps/asr/README.html#start-whisper-service-test">1.2 Start Whisper Service/Test</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../GenAIComps/comps/asr/README.html#start-asr-service-test">1.3 Start ASR Service/Test</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../../GenAIComps/comps/asr/README.html#start-microservice-with-docker-option-2">🚀2. Start Microservice with Docker (Option 2)</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../../GenAIComps/comps/asr/README.html#build-images">2.1 Build Images</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../../GenAIComps/comps/asr/README.html#whisper-server-image">2.1.1 Whisper Server Image</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../GenAIComps/comps/asr/README.html#asr-service-image">2.1.2 ASR Service Image</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../../GenAIComps/comps/asr/README.html#start-whisper-and-asr-service">2.2 Start Whisper and ASR Service</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../../GenAIComps/comps/asr/README.html#start-whisper-server">2.2.1 Start Whisper Server</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../GenAIComps/comps/asr/README.html#start-asr-service">2.2.2 Start ASR service</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../GenAIComps/comps/asr/README.html#test">2.2.3 Test</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../../GenAIComps/comps/dataprep/README.html">Dataprep Microservice</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../../GenAIComps/comps/dataprep/README.html#install-requirements">Install Requirements</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../GenAIComps/comps/dataprep/README.html#use-lvm-large-vision-model-for-summarizing-image-data">Use LVM (Large Vision Model) for Summarizing Image Data</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../../GenAIComps/comps/dataprep/README.html#dataprep-microservice-with-redis">Dataprep Microservice with Redis</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../GenAIComps/comps/dataprep/README.html#dataprep-microservice-with-milvus">Dataprep Microservice with Milvus</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../GenAIComps/comps/dataprep/README.html#dataprep-microservice-with-qdrant">Dataprep Microservice with Qdrant</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../GenAIComps/comps/dataprep/README.html#dataprep-microservice-with-pinecone">Dataprep Microservice with Pinecone</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../GenAIComps/comps/dataprep/README.html#dataprep-microservice-with-pgvector">Dataprep Microservice with PGVector</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../GenAIComps/comps/embeddings/README.html">Embeddings Microservice</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../GenAIComps/comps/embeddings/README.html#start-microservice-with-python-option-1">🚀1. Start Microservice with Python (Option 1)</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../../GenAIComps/comps/embeddings/README.html#install-requirements">1.1 Install Requirements</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../GenAIComps/comps/embeddings/README.html#start-embedding-service">1.2 Start Embedding Service</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../../GenAIComps/comps/embeddings/README.html#start-embedding-service-with-tei">Start Embedding Service with TEI</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../GenAIComps/comps/embeddings/README.html#start-embedding-service-with-local-model">Start Embedding Service with Local Model</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../../GenAIComps/comps/embeddings/README.html#start-microservice-with-docker-optional-2">🚀2. Start Microservice with Docker (Optional 2)</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../../GenAIComps/comps/embeddings/README.html#id1">2.1 Start Embedding Service with TEI</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../GenAIComps/comps/embeddings/README.html#build-docker-image">2.2 Build Docker Image</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../../GenAIComps/comps/embeddings/README.html#build-langchain-docker-option-a">Build Langchain Docker (Option a)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../GenAIComps/comps/embeddings/README.html#build-llamaindex-docker-option-b">Build LlamaIndex Docker (Option b)</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../../GenAIComps/comps/embeddings/README.html#run-docker-with-cli">2.3 Run Docker with CLI</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../GenAIComps/comps/embeddings/README.html#run-docker-with-docker-compose">2.4 Run Docker with Docker Compose</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../../GenAIComps/comps/embeddings/README.html#consume-embedding-service">🚀3. Consume Embedding Service</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../../GenAIComps/comps/embeddings/README.html#check-service-status">3.1 Check Service Status</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../GenAIComps/comps/embeddings/README.html#id2">3.2 Consume Embedding Service</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../../GenAIComps/comps/guardrails/README.html">Guardrails Microservice</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../GenAIComps/comps/guardrails/README.html#start-microservice-with-python-option-1">🚀1. Start Microservice with Python (Option 1)</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../../GenAIComps/comps/guardrails/README.html#install-requirements">1.1 Install Requirements</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../GenAIComps/comps/guardrails/README.html#start-tgi-gaudi-service">1.2 Start TGI Gaudi Service</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../GenAIComps/comps/guardrails/README.html#verify-the-tgi-gaudi-service">1.3 Verify the TGI Gaudi Service</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../GenAIComps/comps/guardrails/README.html#start-guardrails-service">1.4 Start Guardrails Service</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../../GenAIComps/comps/guardrails/README.html#start-microservice-with-docker-option-2">🚀2. Start Microservice with Docker (Option 2)</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../../GenAIComps/comps/guardrails/README.html#setup-environment-variables">2.1 Setup Environment Variables</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../GenAIComps/comps/guardrails/README.html#build-docker-image">2.2 Build Docker Image</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../GenAIComps/comps/guardrails/README.html#run-docker-with-cli">2.3 Run Docker with CLI</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../GenAIComps/comps/guardrails/README.html#run-docker-with-docker-compose">2.4 Run Docker with Docker Compose</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../../GenAIComps/comps/guardrails/README.html#consume-guardrails-service">🚀3. Consume Guardrails Service</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../../GenAIComps/comps/guardrails/README.html#check-service-status">3.1 Check Service Status</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../GenAIComps/comps/guardrails/README.html#id1">3.2 Consume Guardrails Service</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../../GenAIComps/comps/knowledgegraphs/README.html">Knowledge Graph Microservice</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../GenAIComps/comps/knowledgegraphs/README.html#start-microservice-with-docker">🚀1. Start Microservice with Docker</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../../GenAIComps/comps/knowledgegraphs/README.html#setup-environment-variables">1.1 Setup Environment Variables</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../GenAIComps/comps/knowledgegraphs/README.html#start-neo4j-service">1.2 Start Neo4j Service</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../GenAIComps/comps/knowledgegraphs/README.html#start-llm-service-for-rag-query-mode">1.3 Start LLM Service for “rag”/”query” mode</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../GenAIComps/comps/knowledgegraphs/README.html#start-microservice">1.4 Start Microservice</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../../GenAIComps/comps/knowledgegraphs/README.html#consume-knowledge-graph-service">🚀2. Consume Knowledge Graph Service</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../../GenAIComps/comps/knowledgegraphs/README.html#cypher-mode">2.1 Cypher mode</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../GenAIComps/comps/knowledgegraphs/README.html#rag-mode">2.2 Rag mode</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../GenAIComps/comps/knowledgegraphs/README.html#query-mode">2.3 Query mode</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../../GenAIComps/comps/llms/README.html">LLM Microservice</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../GenAIComps/comps/llms/README.html#start-microservice-with-python-option-1">🚀1. Start Microservice with Python (Option 1)</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../../GenAIComps/comps/llms/README.html#install-requirements">1.1 Install Requirements</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../GenAIComps/comps/llms/README.html#start-llm-service">1.2 Start LLM Service</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../../GenAIComps/comps/llms/README.html#start-tgi-service">1.2.1 Start TGI Service</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../GenAIComps/comps/llms/README.html#start-vllm-service">1.2.2 Start vLLM Service</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../../GenAIComps/comps/llms/README.html#start-ray-service">1.2.3 Start Ray Service</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../GenAIComps/comps/llms/README.html#verify-the-llm-service">1.3 Verify the LLM Service</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../../GenAIComps/comps/llms/README.html#verify-the-tgi-service">1.3.1 Verify the TGI Service</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../GenAIComps/comps/llms/README.html#verify-the-vllm-service">1.3.2 Verify the vLLM Service</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../GenAIComps/comps/llms/README.html#verify-the-ray-service">1.3.3 Verify the Ray Service</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../../GenAIComps/comps/llms/README.html#start-llm-service-with-python-script">1.4 Start LLM Service with Python Script</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../../GenAIComps/comps/llms/README.html#start-the-tgi-service">1.4.1 Start the TGI Service</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../GenAIComps/comps/llms/README.html#start-the-vllm-service">1.4.2 Start the vLLM Service</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../GenAIComps/comps/llms/README.html#start-the-ray-service">1.4.3 Start the Ray Service</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../../GenAIComps/comps/llms/README.html#start-microservice-with-docker-option-2">🚀2. Start Microservice with Docker (Option 2)</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../../GenAIComps/comps/llms/README.html#setup-environment-variables">2.1 Setup Environment Variables</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../GenAIComps/comps/llms/README.html#build-docker-image">2.2 Build Docker Image</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../../GenAIComps/comps/llms/README.html#tgi">2.2.1 TGI</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../GenAIComps/comps/llms/README.html#vllm">2.2.2 vLLM</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../GenAIComps/comps/llms/README.html#ray-serve">2.2.3 Ray Serve</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../../GenAIComps/comps/llms/README.html#run-docker-with-cli-option-a">2.3 Run Docker with CLI (Option A)</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../../GenAIComps/comps/llms/README.html#id1">2.3.1 TGI</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../GenAIComps/comps/llms/README.html#id2">2.3.2 vLLM</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../GenAIComps/comps/llms/README.html#id3">2.3.3 Ray Serve</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../../GenAIComps/comps/llms/README.html#run-docker-with-docker-compose-option-b">2.4 Run Docker with Docker Compose (Option B)</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../../GenAIComps/comps/llms/README.html#id4">2.4.1 TGI</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../GenAIComps/comps/llms/README.html#id5">2.4.2 vLLM</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../GenAIComps/comps/llms/README.html#id6">2.4.3 Ray Serve</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../../GenAIComps/comps/llms/README.html#consume-llm-service">🚀3. Consume LLM Service</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../../GenAIComps/comps/llms/README.html#check-service-status">3.1 Check Service Status</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../GenAIComps/comps/llms/README.html#id7">3.2 Consume LLM Service</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../GenAIComps/comps/llms/README.html#validated-model">4. Validated Model</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../../GenAIComps/comps/lvms/README.html">LVM Microservice</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../GenAIComps/comps/lvms/README.html#start-microservice-with-python-option-1">🚀1. Start Microservice with Python (Option 1)</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../../GenAIComps/comps/lvms/README.html#install-requirements">1.1 Install Requirements</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../GenAIComps/comps/lvms/README.html#start-llava-service-test">1.2 Start LLaVA Service/Test</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../GenAIComps/comps/lvms/README.html#start-image-to-text-service-test">1.3 Start Image To Text Service/Test</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../../GenAIComps/comps/lvms/README.html#start-microservice-with-docker-option-2">🚀2. Start Microservice with Docker (Option 2)</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../../GenAIComps/comps/lvms/README.html#build-images">2.1 Build Images</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../../GenAIComps/comps/lvms/README.html#llava-server-image">2.1.1 LLaVA Server Image</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../GenAIComps/comps/lvms/README.html#lvm-service-image">2.1.2 LVM Service Image</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../../GenAIComps/comps/lvms/README.html#start-llava-and-lvm-service">2.2 Start LLaVA and LVM Service</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../../GenAIComps/comps/lvms/README.html#start-llava-server">2.2.1 Start LLaVA server</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../GenAIComps/comps/lvms/README.html#start-lvm-service">2.2.2 Start LVM service</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../GenAIComps/comps/lvms/README.html#test">2.2.3 Test</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../../GenAIComps/comps/reranks/README.html">Reranking Microservice</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../GenAIComps/comps/reranks/README.html#start-microservice-with-python-option-1">🚀1. Start Microservice with Python (Option 1)</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../../GenAIComps/comps/reranks/README.html#install-requirements">1.1 Install Requirements</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../GenAIComps/comps/reranks/README.html#start-tei-service">1.2 Start TEI Service</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../GenAIComps/comps/reranks/README.html#verify-the-tei-service">1.3 Verify the TEI Service</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../GenAIComps/comps/reranks/README.html#start-reranking-service-with-python-script">1.4 Start Reranking Service with Python Script</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../../GenAIComps/comps/reranks/README.html#start-microservice-with-docker-option-2">🚀2. Start Microservice with Docker (Option 2)</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../../GenAIComps/comps/reranks/README.html#setup-environment-variables">2.1 Setup Environment Variables</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../GenAIComps/comps/reranks/README.html#build-docker-image">2.2 Build Docker Image</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../GenAIComps/comps/reranks/README.html#run-docker-with-cli-option-a">2.3 Run Docker with CLI (Option A)</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../GenAIComps/comps/reranks/README.html#run-docker-with-docker-compose-option-b">2.4 Run Docker with Docker Compose (Option B)</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../../GenAIComps/comps/reranks/README.html#consume-reranking-service">🚀3. Consume Reranking Service</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../../GenAIComps/comps/reranks/README.html#check-service-status">3.1 Check Service Status</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../GenAIComps/comps/reranks/README.html#id1">3.2 Consume Reranking Service</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../../GenAIComps/comps/tts/README.html">TTS Microservice</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../../GenAIComps/comps/tts/README.html#start-speecht5-service-test">1.2 Start SpeechT5 Service/Test</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../GenAIComps/comps/tts/README.html#start-tts-service-test">1.3 Start TTS Service/Test</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../../GenAIComps/comps/tts/README.html#start-microservice-with-docker-option-2">🚀2. Start Microservice with Docker (Option 2)</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../../GenAIComps/comps/tts/README.html#build-images">2.1 Build Images</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../../GenAIComps/comps/tts/README.html#whisper-server-image">2.1.1 Whisper Server Image</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../GenAIComps/comps/tts/README.html#tts-service-image">2.1.2 TTS Service Image</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../../GenAIComps/comps/tts/README.html#start-speecht5-and-tts-service">2.2 Start SpeechT5 and TTS Service</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../../GenAIComps/comps/tts/README.html#start-speecht5-server">2.2.1 Start SpeechT5 Server</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../GenAIComps/comps/tts/README.html#start-tts-service">2.2.2 Start TTS service</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../GenAIComps/comps/tts/README.html#test">2.2.3 Test</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../../GenAIComps/comps/vectorstores/README.html">Vectorstores Microservice</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../GenAIComps/comps/vectorstores/README.html#vectorstores-microservice-with-redis">Vectorstores Microservice with Redis</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../GenAIComps/comps/vectorstores/README.html#vectorstores-microservice-with-qdrant">Vectorstores Microservice with Qdrant</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../GenAIComps/comps/vectorstores/README.html#vectorstores-microservice-with-pgvector">Vectorstores Microservice with PGVector</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../GenAIComps/comps/vectorstores/README.html#vectorstores-microservice-with-pinecone">Vectorstores Microservice with Pinecone</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../GenAIComps/comps/dataprep/milvus/README.html">Dataprep Microservice with Milvus</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../GenAIComps/comps/dataprep/milvus/README.html#start-microservice-with-python">🚀Start Microservice with Python</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../../GenAIComps/comps/dataprep/milvus/README.html#install-requirements">Install Requirements</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../GenAIComps/comps/dataprep/milvus/README.html#start-milvus-server">Start Milvus Server</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../GenAIComps/comps/dataprep/milvus/README.html#setup-environment-variables">Setup Environment Variables</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../GenAIComps/comps/dataprep/milvus/README.html#start-document-preparation-microservice-for-milvus-with-python-script">Start Document Preparation Microservice for Milvus with Python Script</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../../GenAIComps/comps/dataprep/milvus/README.html#start-microservice-with-docker">🚀Start Microservice with Docker</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../../GenAIComps/comps/dataprep/milvus/README.html#build-docker-image">Build Docker Image</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../GenAIComps/comps/dataprep/milvus/README.html#run-docker-with-cli">Run Docker with CLI</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../../GenAIComps/comps/dataprep/milvus/README.html#invoke-microservice">Invoke Microservice</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../GenAIComps/comps/dataprep/pgvector/README.html">Dataprep Microservice with PGVector</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../GenAIComps/comps/dataprep/pgvector/README.html#start-microservice-with-python-option-1">🚀1. Start Microservice with Python（Option 1）</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../../GenAIComps/comps/dataprep/pgvector/README.html#install-requirements">1.1 Install Requirements</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../GenAIComps/comps/dataprep/pgvector/README.html#start-pgvector">1.2 Start PGVector</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../GenAIComps/comps/dataprep/pgvector/README.html#setup-environment-variables">1.3 Setup Environment Variables</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../GenAIComps/comps/dataprep/pgvector/README.html#start-document-preparation-microservice-for-pgvector-with-python-script">1.4 Start Document Preparation Microservice for PGVector with Python Script</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../../GenAIComps/comps/dataprep/pgvector/README.html#start-microservice-with-docker-option-2">🚀2. Start Microservice with Docker (Option 2)</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../../GenAIComps/comps/dataprep/pgvector/README.html#id1">2.1 Start PGVector</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../GenAIComps/comps/dataprep/pgvector/README.html#id2">2.2 Setup Environment Variables</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../GenAIComps/comps/dataprep/pgvector/README.html#build-docker-image">2.3 Build Docker Image</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../GenAIComps/comps/dataprep/pgvector/README.html#run-docker-with-cli-option-a">2.4 Run Docker with CLI (Option A)</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../GenAIComps/comps/dataprep/pgvector/README.html#run-with-docker-compose-option-b">2.5 Run with Docker Compose (Option B)</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../../GenAIComps/comps/dataprep/pgvector/README.html#consume-microservice">🚀3. Consume Microservice</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../GenAIComps/comps/dataprep/pinecone/README.html">Dataprep Microservice with Pinecone</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../GenAIComps/comps/dataprep/pinecone/README.html#start-microservice-with-python">🚀Start Microservice with Python</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../../GenAIComps/comps/dataprep/pinecone/README.html#install-requirements">Install Requirements</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../GenAIComps/comps/dataprep/pinecone/README.html#start-pinecone-server">Start Pinecone Server</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../GenAIComps/comps/dataprep/pinecone/README.html#setup-environment-variables">Setup Environment Variables</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../GenAIComps/comps/dataprep/pinecone/README.html#start-document-preparation-microservice-for-pinecone-with-python-script">Start Document Preparation Microservice for Pinecone with Python Script</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../../GenAIComps/comps/dataprep/pinecone/README.html#start-microservice-with-docker">🚀Start Microservice with Docker</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../../GenAIComps/comps/dataprep/pinecone/README.html#build-docker-image">Build Docker Image</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../GenAIComps/comps/dataprep/pinecone/README.html#run-docker-with-cli">Run Docker with CLI</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../GenAIComps/comps/dataprep/pinecone/README.html#id1">Setup Environment Variables</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../GenAIComps/comps/dataprep/pinecone/README.html#run-docker-with-docker-compose">Run Docker with Docker Compose</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../../GenAIComps/comps/dataprep/pinecone/README.html#invoke-microservice">Invoke Microservice</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../GenAIComps/comps/dataprep/qdrant/README.html">Dataprep Microservice with Qdrant</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../GenAIComps/comps/dataprep/qdrant/README.html#start-microservice-with-python">🚀Start Microservice with Python</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../../GenAIComps/comps/dataprep/qdrant/README.html#install-requirements">Install Requirements</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../GenAIComps/comps/dataprep/qdrant/README.html#start-qdrant-server">Start Qdrant Server</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../GenAIComps/comps/dataprep/qdrant/README.html#setup-environment-variables">Setup Environment Variables</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../GenAIComps/comps/dataprep/qdrant/README.html#start-document-preparation-microservice-for-qdrant-with-python-script">Start Document Preparation Microservice for Qdrant with Python Script</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../../GenAIComps/comps/dataprep/qdrant/README.html#start-microservice-with-docker">🚀Start Microservice with Docker</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../../GenAIComps/comps/dataprep/qdrant/README.html#build-docker-image">Build Docker Image</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../GenAIComps/comps/dataprep/qdrant/README.html#run-docker-with-cli">Run Docker with CLI</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../GenAIComps/comps/dataprep/qdrant/README.html#id1">Setup Environment Variables</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../GenAIComps/comps/dataprep/qdrant/README.html#run-docker-with-docker-compose">Run Docker with Docker Compose</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../../GenAIComps/comps/dataprep/qdrant/README.html#invoke-microservice">Invoke Microservice</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../GenAIComps/comps/dataprep/redis/README.html">Dataprep Microservice with Redis</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../GenAIComps/comps/dataprep/redis/README.html#start-microservice-with-python-option-1">🚀1. Start Microservice with Python（Option 1）</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../../GenAIComps/comps/dataprep/redis/README.html#install-requirements">1.1 Install Requirements</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../GenAIComps/comps/dataprep/redis/README.html#start-redis-stack-server">1.2 Start Redis Stack Server</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../GenAIComps/comps/dataprep/redis/README.html#setup-environment-variables">1.3 Setup Environment Variables</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../GenAIComps/comps/dataprep/redis/README.html#start-document-preparation-microservice-for-redis-with-python-script">1.4 Start Document Preparation Microservice for Redis with Python Script</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../../GenAIComps/comps/dataprep/redis/README.html#start-microservice-with-docker-option-2">🚀2. Start Microservice with Docker (Option 2)</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../../GenAIComps/comps/dataprep/redis/README.html#id1">2.1 Start Redis Stack Server</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../GenAIComps/comps/dataprep/redis/README.html#id2">2.2 Setup Environment Variables</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../GenAIComps/comps/dataprep/redis/README.html#build-docker-image">2.3 Build Docker Image</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../GenAIComps/comps/dataprep/redis/README.html#run-docker-with-cli-option-a">2.4 Run Docker with CLI (Option A)</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../GenAIComps/comps/dataprep/redis/README.html#run-with-docker-compose-option-b-deprecated-will-move-to-genaiexample-in-future">2.5 Run with Docker Compose (Option B - deprecated, will move to genAIExample in future)</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../../GenAIComps/comps/dataprep/redis/README.html#status-microservice">🚀3. Status Microservice</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../GenAIComps/comps/dataprep/redis/README.html#consume-microservice">🚀4. Consume Microservice</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../../GenAIComps/comps/dataprep/redis/README.html#consume-upload-api">4.1 Consume Upload API</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../GenAIComps/comps/dataprep/redis/README.html#consume-get-file-api">4.2 Consume get_file API</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../GenAIComps/comps/dataprep/redis/README.html#consume-delete-file-api">4.3 Consume delete_file API</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../../GenAIComps/comps/embeddings/langchain-mosec/README.html">build Mosec endpoint docker image</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../GenAIComps/comps/embeddings/langchain-mosec/README.html#build-embedding-microservice-docker-image">build embedding microservice docker image</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../GenAIComps/comps/embeddings/langchain-mosec/README.html#launch-mosec-endpoint-docker-container">launch Mosec endpoint docker container</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../GenAIComps/comps/embeddings/langchain-mosec/README.html#launch-embedding-microservice-docker-container">launch embedding microservice docker container</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../GenAIComps/comps/embeddings/langchain-mosec/README.html#run-client-test">run client test</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../GenAIComps/comps/guardrails/pii_detection/README.html">PII Detection Microservice</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../GenAIComps/comps/guardrails/pii_detection/README.html#start-microservice-with-python-option-1">🚀1. Start Microservice with Python（Option 1）</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../../GenAIComps/comps/guardrails/pii_detection/README.html#install-requirements">1.1 Install Requirements</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../GenAIComps/comps/guardrails/pii_detection/README.html#start-pii-detection-microservice-with-python-script">1.2 Start PII Detection Microservice with Python Script</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../../GenAIComps/comps/guardrails/pii_detection/README.html#start-microservice-with-docker-option-2">🚀2. Start Microservice with Docker (Option 2)</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../../GenAIComps/comps/guardrails/pii_detection/README.html#prepare-pii-detection-model">2.1 Prepare PII detection model</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../GenAIComps/comps/guardrails/pii_detection/README.html#use-llm-endpoint-will-add-later">2.1.1 use LLM endpoint (will add later)</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../GenAIComps/comps/guardrails/pii_detection/README.html#build-docker-image">2.2 Build Docker Image</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../GenAIComps/comps/guardrails/pii_detection/README.html#run-docker-with-cli">2.3 Run Docker with CLI</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../../GenAIComps/comps/guardrails/pii_detection/README.html#get-status-of-microservice">🚀3. Get Status of Microservice</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../GenAIComps/comps/guardrails/pii_detection/README.html#consume-microservice">🚀4. Consume Microservice</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../GenAIComps/comps/reranks/fastrag/README.html">Reranking Microservice</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../GenAIComps/comps/reranks/fastrag/README.html#start-microservice-with-python-option-1">🚀1. Start Microservice with Python (Option 1)</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../../GenAIComps/comps/reranks/fastrag/README.html#install-requirements">1.1 Install Requirements</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../GenAIComps/comps/reranks/fastrag/README.html#install-fastrag">1.2 Install fastRAG</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../GenAIComps/comps/reranks/fastrag/README.html#start-reranking-service-with-python-script">1.3 Start Reranking Service with Python Script</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../../GenAIComps/comps/reranks/fastrag/README.html#start-microservice-with-docker-option-2">🚀2. Start Microservice with Docker (Option 2)</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../../GenAIComps/comps/reranks/fastrag/README.html#setup-environment-variables">2.1 Setup Environment Variables</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../GenAIComps/comps/reranks/fastrag/README.html#build-docker-image">2.2 Build Docker Image</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../GenAIComps/comps/reranks/fastrag/README.html#run-docker">2.3 Run Docker</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../../GenAIComps/comps/reranks/fastrag/README.html#consume-reranking-service">🚀3. Consume Reranking Service</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../../GenAIComps/comps/reranks/fastrag/README.html#check-service-status">3.1 Check Service Status</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../GenAIComps/comps/reranks/fastrag/README.html#id1">3.2 Consume Reranking Service</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../../GenAIComps/comps/reranks/langchain-mosec/README.html">build reranking Mosec endpoint docker image</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../GenAIComps/comps/reranks/langchain-mosec/README.html#build-reranking-microservice-docker-image">build reranking microservice docker image</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../GenAIComps/comps/reranks/langchain-mosec/README.html#launch-mosec-endpoint-docker-container">launch Mosec endpoint docker container</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../GenAIComps/comps/reranks/langchain-mosec/README.html#launch-embedding-microservice-docker-container">launch embedding microservice docker container</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../GenAIComps/comps/reranks/langchain-mosec/README.html#run-client-test">run client test</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../GenAIComps/comps/retrievers/langchain/README.html">Retriever Microservice</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../GenAIComps/comps/retrievers/langchain/README.html#retriever-microservice-with-redis">Retriever Microservice with Redis</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../GenAIComps/comps/retrievers/langchain/README.html#retriever-microservice-with-milvus">Retriever Microservice with Milvus</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../GenAIComps/comps/retrievers/langchain/README.html#retriever-microservice-with-pgvector">Retriever Microservice with PGVector</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../GenAIComps/comps/retrievers/llamaindex/README.html">Retriever Microservice</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../GenAIComps/comps/retrievers/llamaindex/README.html#start-microservice-with-python-option-1">🚀1. Start Microservice with Python (Option 1)</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../../GenAIComps/comps/retrievers/llamaindex/README.html#install-requirements">1.1 Install Requirements</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../GenAIComps/comps/retrievers/llamaindex/README.html#setup-vectordb-service">1.2 Setup VectorDB Service</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../GenAIComps/comps/retrievers/llamaindex/README.html#start-retriever-service">1.3 Start Retriever Service</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../../GenAIComps/comps/retrievers/llamaindex/README.html#start-microservice-with-docker-option-2">🚀2. Start Microservice with Docker (Option 2)</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../../GenAIComps/comps/retrievers/llamaindex/README.html#setup-environment-variables">2.1 Setup Environment Variables</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../GenAIComps/comps/retrievers/llamaindex/README.html#build-docker-image">2.2 Build Docker Image</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../GenAIComps/comps/retrievers/llamaindex/README.html#run-docker-with-cli-option-a">2.3 Run Docker with CLI (Option A)</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../GenAIComps/comps/retrievers/llamaindex/README.html#run-docker-with-docker-compose-option-b">2.4 Run Docker with Docker Compose (Option B)</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../../GenAIComps/comps/retrievers/llamaindex/README.html#consume-retriever-service">🚀3. Consume Retriever Service</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../../GenAIComps/comps/retrievers/llamaindex/README.html#check-service-status">3.1 Check Service Status</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../GenAIComps/comps/retrievers/llamaindex/README.html#id1">3.2 Consume Retriever Service</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../../GenAIComps/comps/embeddings/langchain-mosec/mosec-docker/README.html">Embedding Server</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../../GenAIComps/comps/embeddings/langchain-mosec/mosec-docker/README.html#introduction">1. Introduction</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../GenAIComps/comps/embeddings/langchain-mosec/mosec-docker/README.html#quick-start">2. Quick Start</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../../GenAIComps/comps/embeddings/langchain-mosec/mosec-docker/README.html#build-docker-image">2.1 Build Docker image</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../GenAIComps/comps/embeddings/langchain-mosec/mosec-docker/README.html#launch-server">2.2 Launch server</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../GenAIComps/comps/embeddings/langchain-mosec/mosec-docker/README.html#client-test">2.3 Client test</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../../GenAIComps/comps/llms/text-generation/ollama/README.html">Introduction</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../GenAIComps/comps/llms/text-generation/ollama/README.html#get-started">Get Started</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../../GenAIComps/comps/llms/text-generation/ollama/README.html#setup">Setup</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../GenAIComps/comps/llms/text-generation/ollama/README.html#usage">Usage</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../../GenAIComps/comps/llms/text-generation/ollama/README.html#in-the-terminal">In the terminal</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../GenAIComps/comps/llms/text-generation/ollama/README.html#api-access">API access</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../../GenAIComps/comps/llms/text-generation/ollama/README.html#build-docker-image">Build Docker Image</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../GenAIComps/comps/llms/text-generation/ollama/README.html#run-the-ollama-microservice">Run the Ollama Microservice</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../GenAIComps/comps/llms/text-generation/ollama/README.html#consume-the-ollama-microservice">Consume the Ollama Microservice</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../GenAIComps/comps/llms/text-generation/ray_serve/README.html">Ray-Serve Endpoint Service</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../../GenAIComps/comps/llms/text-generation/ray_serve/README.html#getting-started">Getting Started</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../../GenAIComps/comps/llms/text-generation/ray_serve/README.html#launch-ray-gaudi-service">Launch Ray Gaudi Service</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../../GenAIComps/comps/llms/text-generation/tgi/README.html">TGI LLM Microservice</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../GenAIComps/comps/llms/text-generation/tgi/README.html#start-microservice-with-python-option-1">🚀1. Start Microservice with Python (Option 1)</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../../GenAIComps/comps/llms/text-generation/tgi/README.html#install-requirements">1.1 Install Requirements</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../GenAIComps/comps/llms/text-generation/tgi/README.html#start-llm-service">1.2 Start LLM Service</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../GenAIComps/comps/llms/text-generation/tgi/README.html#verify-the-tgi-service">1.3 Verify the TGI Service</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../GenAIComps/comps/llms/text-generation/tgi/README.html#start-llm-service-with-python-script">1.4 Start LLM Service with Python Script</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../../GenAIComps/comps/llms/text-generation/tgi/README.html#start-microservice-with-docker-option-2">🚀2. Start Microservice with Docker (Option 2)</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../../GenAIComps/comps/llms/text-generation/tgi/README.html#setup-environment-variables">2.1 Setup Environment Variables</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../GenAIComps/comps/llms/text-generation/tgi/README.html#build-docker-image">2.2 Build Docker Image</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../GenAIComps/comps/llms/text-generation/tgi/README.html#run-docker-with-cli-option-a">2.3 Run Docker with CLI (Option A)</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../GenAIComps/comps/llms/text-generation/tgi/README.html#run-docker-with-docker-compose-option-b">2.4 Run Docker with Docker Compose (Option B)</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../../GenAIComps/comps/llms/text-generation/tgi/README.html#consume-llm-service">🚀3. Consume LLM Service</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../../GenAIComps/comps/llms/text-generation/tgi/README.html#check-service-status">3.1 Check Service Status</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../GenAIComps/comps/llms/text-generation/tgi/README.html#id1">3.2 Consume LLM Service</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../GenAIComps/comps/llms/text-generation/tgi/README.html#validated-model">4. Validated Model</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../../GenAIComps/comps/llms/text-generation/vllm-openvino/README.html">Use vLLM with OpenVINO</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../../GenAIComps/comps/llms/text-generation/vllm-openvino/README.html#build-docker-image">Build Docker Image</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../GenAIComps/comps/llms/text-generation/vllm-openvino/README.html#use-vllm-serving-with-openai-api">Use vLLM serving with OpenAI API</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../../GenAIComps/comps/llms/text-generation/vllm-openvino/README.html#start-the-server">Start The Server:</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../GenAIComps/comps/llms/text-generation/vllm-openvino/README.html#request-completion-with-curl">Request Completion With Curl:</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../../GenAIComps/comps/llms/text-generation/vllm-openvino/README.html#use-int-8-weights-compression">Use Int-8 Weights Compression</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../GenAIComps/comps/llms/text-generation/vllm-openvino/README.html#use-uint-8-kv-cache-compression">Use UInt-8 KV cache Compression</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../../GenAIComps/comps/llms/text-generation/vllm-xft/README.html">🚀 Start Microservice with Docker</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../../GenAIComps/comps/llms/text-generation/vllm-xft/README.html#build-docker-image">1 Build Docker Image</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../GenAIComps/comps/llms/text-generation/vllm-xft/README.html#run-docker-with-cli">2 Run Docker with CLI</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../../GenAIComps/comps/llms/text-generation/vllm-xft/README.html#consume-llm-service">🚀3. Consume LLM Service</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../../GenAIComps/comps/llms/text-generation/vllm-xft/README.html#check-service-status">3.1 Check Service Status</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../GenAIComps/comps/llms/text-generation/vllm-xft/README.html#id1">3.2 Consume LLM Service</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../../GenAIComps/comps/llms/text-generation/vllm/README.html">vLLM Endpoint Serve</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../../GenAIComps/comps/llms/text-generation/vllm/README.html#vllm-on-cpu">vLLM on CPU</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../../GenAIComps/comps/llms/text-generation/vllm/README.html#build-docker">Build docker</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../GenAIComps/comps/llms/text-generation/vllm/README.html#launch-vllm-service">Launch vLLM service</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../../GenAIComps/comps/llms/text-generation/vllm/README.html#vllm-on-gaudi">vLLM on Gaudi</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../../GenAIComps/comps/llms/text-generation/vllm/README.html#id1">Build docker</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../GenAIComps/comps/llms/text-generation/vllm/README.html#launch-vllm-service-on-single-node">Launch vLLM service on single node</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../GenAIComps/comps/llms/text-generation/vllm/README.html#launch-vllm-service-on-multiple-nodes">Launch vLLM service on multiple nodes</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../../GenAIComps/comps/llms/text-generation/vllm/README.html#query-the-service">Query the service</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../../GenAIComps/comps/llms/utils/lm-eval/README.html">LM-Eval Microservice</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../../GenAIComps/comps/llms/utils/lm-eval/README.html#cpu-service">CPU service</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../../GenAIComps/comps/llms/utils/lm-eval/README.html#build-cpu-docker">build cpu docker</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../GenAIComps/comps/llms/utils/lm-eval/README.html#start-the-server">start the server</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../GenAIComps/comps/llms/utils/lm-eval/README.html#evaluate-the-model">evaluate the model</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../../GenAIComps/comps/retrievers/haystack/qdrant/README.html">Retriever Microservice with Qdrant</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../GenAIComps/comps/retrievers/haystack/qdrant/README.html#start-microservice-with-python">🚀Start Microservice with Python</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../../GenAIComps/comps/retrievers/haystack/qdrant/README.html#install-requirements">Install Requirements</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../GenAIComps/comps/retrievers/haystack/qdrant/README.html#start-qdrant-server">Start Qdrant Server</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../GenAIComps/comps/retrievers/haystack/qdrant/README.html#setup-environment-variables">Setup Environment Variables</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../GenAIComps/comps/retrievers/haystack/qdrant/README.html#start-retriever-service">Start Retriever Service</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../../GenAIComps/comps/retrievers/haystack/qdrant/README.html#start-microservice-with-docker">🚀Start Microservice with Docker</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../../GenAIComps/comps/retrievers/haystack/qdrant/README.html#build-docker-image">Build Docker Image</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../GenAIComps/comps/retrievers/haystack/qdrant/README.html#run-docker-with-cli">Run Docker with CLI</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../../GenAIComps/comps/retrievers/haystack/qdrant/README.html#consume-retriever-service">🚀3. Consume Retriever Service</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../../GenAIComps/comps/retrievers/haystack/qdrant/README.html#check-service-status">3.1 Check Service Status</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../GenAIComps/comps/retrievers/haystack/qdrant/README.html#consume-embedding-service">3.2 Consume Embedding Service</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../../GenAIComps/comps/retrievers/langchain/milvus/README.html">Retriever Microservice with Milvus</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../GenAIComps/comps/retrievers/langchain/milvus/README.html#start-microservice-with-python">🚀Start Microservice with Python</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../../GenAIComps/comps/retrievers/langchain/milvus/README.html#install-requirements">Install Requirements</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../GenAIComps/comps/retrievers/langchain/milvus/README.html#start-milvus-server">Start Milvus Server</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../GenAIComps/comps/retrievers/langchain/milvus/README.html#setup-environment-variables">Setup Environment Variables</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../GenAIComps/comps/retrievers/langchain/milvus/README.html#start-retriever-service">Start Retriever Service</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../../GenAIComps/comps/retrievers/langchain/milvus/README.html#start-microservice-with-docker">🚀Start Microservice with Docker</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../../GenAIComps/comps/retrievers/langchain/milvus/README.html#build-docker-image">Build Docker Image</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../GenAIComps/comps/retrievers/langchain/milvus/README.html#run-docker-with-cli">Run Docker with CLI</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../../GenAIComps/comps/retrievers/langchain/milvus/README.html#consume-retriever-service">🚀3. Consume Retriever Service</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../../GenAIComps/comps/retrievers/langchain/milvus/README.html#check-service-status">3.1 Check Service Status</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../GenAIComps/comps/retrievers/langchain/milvus/README.html#consume-embedding-service">3.2 Consume Embedding Service</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../../GenAIComps/comps/retrievers/langchain/pgvector/README.html">Retriever Microservice</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../GenAIComps/comps/retrievers/langchain/pgvector/README.html#start-microservice-with-python-option-1">🚀1. Start Microservice with Python (Option 1)</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../../GenAIComps/comps/retrievers/langchain/pgvector/README.html#install-requirements">1.1 Install Requirements</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../GenAIComps/comps/retrievers/langchain/pgvector/README.html#start-tei-service">1.2 Start TEI Service</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../GenAIComps/comps/retrievers/langchain/pgvector/README.html#verify-the-tei-service">1.3 Verify the TEI Service</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../GenAIComps/comps/retrievers/langchain/pgvector/README.html#setup-vectordb-service">1.4 Setup VectorDB Service</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../GenAIComps/comps/retrievers/langchain/pgvector/README.html#start-retriever-service">1.5 Start Retriever Service</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../../GenAIComps/comps/retrievers/langchain/pgvector/README.html#start-microservice-with-docker-option-2">🚀2. Start Microservice with Docker (Option 2)</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../../GenAIComps/comps/retrievers/langchain/pgvector/README.html#setup-environment-variables">2.1 Setup Environment Variables</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../GenAIComps/comps/retrievers/langchain/pgvector/README.html#build-docker-image">2.2 Build Docker Image</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../GenAIComps/comps/retrievers/langchain/pgvector/README.html#run-docker-with-cli-option-a">2.3 Run Docker with CLI (Option A)</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../GenAIComps/comps/retrievers/langchain/pgvector/README.html#run-docker-with-docker-compose-option-b">2.4 Run Docker with Docker Compose (Option B)</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../../GenAIComps/comps/retrievers/langchain/pgvector/README.html#consume-retriever-service">🚀3. Consume Retriever Service</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../../GenAIComps/comps/retrievers/langchain/pgvector/README.html#check-service-status">3.1 Check Service Status</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../GenAIComps/comps/retrievers/langchain/pgvector/README.html#consume-embedding-service">3.2 Consume Embedding Service</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../../GenAIComps/comps/retrievers/langchain/redis/README.html">Retriever Microservice</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../GenAIComps/comps/retrievers/langchain/redis/README.html#start-microservice-with-python-option-1">🚀1. Start Microservice with Python (Option 1)</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../../GenAIComps/comps/retrievers/langchain/redis/README.html#install-requirements">1.1 Install Requirements</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../GenAIComps/comps/retrievers/langchain/redis/README.html#start-tei-service">1.2 Start TEI Service</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../GenAIComps/comps/retrievers/langchain/redis/README.html#verify-the-tei-service">1.3 Verify the TEI Service</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../GenAIComps/comps/retrievers/langchain/redis/README.html#setup-vectordb-service">1.4 Setup VectorDB Service</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../GenAIComps/comps/retrievers/langchain/redis/README.html#start-retriever-service">1.5 Start Retriever Service</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../../GenAIComps/comps/retrievers/langchain/redis/README.html#start-microservice-with-docker-option-2">🚀2. Start Microservice with Docker (Option 2)</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../../GenAIComps/comps/retrievers/langchain/redis/README.html#setup-environment-variables">2.1 Setup Environment Variables</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../GenAIComps/comps/retrievers/langchain/redis/README.html#build-docker-image">2.2 Build Docker Image</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../GenAIComps/comps/retrievers/langchain/redis/README.html#run-docker-with-cli-option-a">2.3 Run Docker with CLI (Option A)</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../GenAIComps/comps/retrievers/langchain/redis/README.html#run-docker-with-docker-compose-option-b">2.4 Run Docker with Docker Compose (Option B)</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../../GenAIComps/comps/retrievers/langchain/redis/README.html#consume-retriever-service">🚀3. Consume Retriever Service</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../../GenAIComps/comps/retrievers/langchain/redis/README.html#check-service-status">3.1 Check Service Status</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../GenAIComps/comps/retrievers/langchain/redis/README.html#consume-embedding-service">3.2 Consume Embedding Service</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../../GenAIComps/comps/vectorstores/langchain/milvus/README.html">Start Milvus server</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../../GenAIComps/comps/vectorstores/langchain/milvus/README.html#configuration">1. Configuration</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../GenAIComps/comps/vectorstores/langchain/milvus/README.html#run-milvus-service">2. Run Milvus service</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../../GenAIComps/comps/vectorstores/langchain/pgvector/README.html">Start PGVector server</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../../GenAIComps/comps/vectorstores/langchain/pgvector/README.html#download-pgvector-image">1. Download Pgvector image</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../GenAIComps/comps/vectorstores/langchain/pgvector/README.html#configure-the-username-password-and-dbname">2. Configure the username, password and dbname</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../GenAIComps/comps/vectorstores/langchain/pgvector/README.html#run-pgvector-service">3. Run Pgvector service</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../../GenAIComps/comps/vectorstores/langchain/pinecone/README.html">Pinecone setup</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../../GenAIComps/comps/vectorstores/langchain/pinecone/README.html#create-pinecone-account-from-the-below-link">1. Create Pinecone account from the below link</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../GenAIComps/comps/vectorstores/langchain/pinecone/README.html#get-api-key">2. Get API key</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../GenAIComps/comps/vectorstores/langchain/pinecone/README.html#create-the-index-in-https-app-pinecone-io">3. Create the index in https://app.pinecone.io/</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../../GenAIComps/comps/vectorstores/langchain/qdrant/README.html">Start Qdrant server</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../../GenAIComps/comps/vectorstores/langchain/qdrant/README.html#download-qdrant-image">1. Download Qdrant image</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../GenAIComps/comps/vectorstores/langchain/qdrant/README.html#run-qdrant-service">2. Run Qdrant service</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../../GenAIComps/comps/vectorstores/langchain/redis/README.html">Start Redis server</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../../GenAIComps/comps/vectorstores/langchain/redis/README.html#download-redis-image">1. Download Redis image</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../GenAIComps/comps/vectorstores/langchain/redis/README.html#run-redis-service">2. Run Redis service</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../../GenAIComps/comps/web_retrievers/langchain/chroma/README.html">Web Retriever Microservice</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../GenAIComps/comps/web_retrievers/langchain/chroma/README.html#start-microservice-with-docker">Start Microservice with Docker</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../../GenAIComps/comps/web_retrievers/langchain/chroma/README.html#build-docker-image">Build Docker Image</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../GenAIComps/comps/web_retrievers/langchain/chroma/README.html#start-tei-service">Start TEI Service</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../GenAIComps/comps/web_retrievers/langchain/chroma/README.html#start-web-retriever-service">Start Web Retriever Service</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../GenAIComps/comps/web_retrievers/langchain/chroma/README.html#consume-web-retriever-service">Consume Web Retriever Service</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../../../GenAIEval.html">Generative AI Evaluation</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../../GenAIEval/README.html">GenAIEval</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../../GenAIEval/README.html#installation">Installation</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../GenAIEval/README.html#evaluation">Evaluation</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../../GenAIEval/README.html#lm-evaluation-harness">lm-evaluation-harness</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../GenAIEval/README.html#bigcode-evaluation-harness">bigcode-evaluation-harness</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../../GenAIEval/README.html#additional-content">Additional Content</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../../GenAIEval/LEGAL_INFORMATION.html">Legal Information</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../../GenAIEval/LEGAL_INFORMATION.html#license">License</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../GenAIEval/LEGAL_INFORMATION.html#citation">Citation</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../../GenAIEval/evals/evaluation/autorag/evaluation/README.html">AutoRAG to evaluate the RAG system performance</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../../GenAIEval/evals/evaluation/autorag/evaluation/README.html#service-preparation">Service preparation</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../GenAIEval/evals/evaluation/autorag/evaluation/README.html#rag-evaluation">RAG evaluation</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../GenAIEval/evals/evaluation/autorag/evaluation/README.html#notes">Notes</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../../../GenAIExamples.html">Generative AI Examples</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../README.html">Generative AI Examples</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../README.html#genai-examples">GenAI Examples</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../README.html#chatqna">ChatQnA</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../README.html#codegen">CodeGen</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../README.html#codetrans">CodeTrans</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../README.html#docsum">DocSum</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../README.html#language-translation">Language Translation</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../README.html#searchqna">SearchQnA</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../README.html#visualqna">VisualQnA</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../README.html#additional-content">Additional Content</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../LEGAL_INFORMATION.html">Legal Information</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../LEGAL_INFORMATION.html#license">License</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../LEGAL_INFORMATION.html#citation">Citation</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../ChatQnA/README.html">ChatQnA Application</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../ChatQnA/README.html#deploy-chatqna-service">Deploy ChatQnA Service</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../ChatQnA/README.html#deploy-chatqna-on-gaudi">Deploy ChatQnA on Gaudi</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../ChatQnA/README.html#deploy-chatqna-on-xeon">Deploy ChatQnA on Xeon</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../ChatQnA/README.html#deploy-chatqna-on-nvidia-gpu">Deploy ChatQnA on NVIDIA GPU</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../ChatQnA/README.html#deploy-chatqna-into-kubernetes-on-xeon-gaudi">Deploy ChatQnA into Kubernetes on Xeon &amp; Gaudi</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../ChatQnA/README.html#deploy-chatqna-on-ai-pc">Deploy ChatQnA on AI PC</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../README.html">Code Generation Application</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../README.html#deploy-codegen-service">Deploy CodeGen Service</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../README.html#deploy-codegen-using-docker">Deploy CodeGen using Docker</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../README.html#deploy-codegen-using-kubernetes">Deploy CodeGen using Kubernetes</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../CodeTrans/README.html">Code Translation Application</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../CodeTrans/README.html#deploy-code-translation-service">Deploy Code Translation Service</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../CodeTrans/README.html#deploy-with-docker">Deploy with Docker</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../CodeTrans/README.html#deploy-with-kubernetes">Deploy with Kubernetes</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../DocSum/README.html">Document Summarization Application</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../DocSum/README.html#deploy-document-summarization-service">Deploy Document Summarization Service</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../DocSum/README.html#deploy-using-docker">Deploy using Docker</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../DocSum/README.html#deploy-using-kubernetes">Deploy using Kubernetes</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../SearchQnA/README.html">SearchQnA Application</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../SearchQnA/README.html#deploy-searchqna-service">Deploy SearchQnA Service</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../SearchQnA/README.html#deploy-searchqna-on-xeon">Deploy SearchQnA on Xeon</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../SearchQnA/README.html#deploy-searchqna-on-gaudi">Deploy SearchQnA on Gaudi</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../Translation/README.html">Translation Application</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../Translation/README.html#deploy-translation-service">Deploy Translation Service</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../Translation/README.html#deploy-translation-on-gaudi">Deploy Translation on Gaudi</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../Translation/README.html#deploy-translation-on-xeon">Deploy Translation on Xeon</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../VisualQnA/README.html">Visual Question and Answering</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../VisualQnA/README.html#start-the-llava-service">Start the LLaVA service</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../VisualQnA/README.html#start-the-gradio-app">Start the Gradio app</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../VisualQnA/README.html#english-interface-default">English Interface (Default)</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../VisualQnA/README.html#chinese-interface">Chinese Interface</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../../../GenAIInfra.html">Generative Containerization and Cloud Native Suite</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../../GenAIInfra/README.html">GenAIInfra</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../../GenAIInfra/README.html#overview">Overview</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../GenAIInfra/README.html#prerequisite">Prerequisite</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../../GenAIInfra/README.html#setup-kubernetes-cluster">Setup Kubernetes cluster</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../GenAIInfra/README.html#optional-to-run-genaiinfra-on-intel-gaudi-product">(Optional) To run GenAIInfra on Intel Gaudi product:</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../../GenAIInfra/README.html#usages">Usages</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../../GenAIInfra/README.html#use-helm-charts-to-deploy">Use helm charts to deploy</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../GenAIInfra/README.html#use-manifests-to-deploy">Use manifests to deploy</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../../GenAIInfra/README.html#additional-content">Additional Content</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../../GenAIInfra/DEVELOPMENT.html">Development</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../../GenAIInfra/DEVELOPMENT.html#prerequisites">Prerequisites</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../GenAIInfra/DEVELOPMENT.html#testing">Testing</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../GenAIInfra/DEVELOPMENT.html#pre-commit-testing">pre-commit testing</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../../GenAIInfra/LEGAL_INFORMATION.html">Legal Information</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../../GenAIInfra/LEGAL_INFORMATION.html#license">License</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../GenAIInfra/LEGAL_INFORMATION.html#citation">Citation</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../../GenAIInfra/helm-charts/README.html">Helm charts for deploying GenAIExamples</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../GenAIInfra/kubernetes-addons/README.html">Deploy Kubernetes add-ons for OPEA</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../GenAIInfra/manifests/README.html">Manifests for deploying GenAIExamples on Kubernetes</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../GenAIInfra/microservices-connector/README.html">genai-microservices-connector(GMC)</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../../GenAIInfra/microservices-connector/README.html#description">Description</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../GenAIInfra/microservices-connector/README.html#architecture">Architecture</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../GenAIInfra/microservices-connector/README.html#personas">Personas</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../GenAIInfra/microservices-connector/README.html#getting-started">Getting Started</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../../GenAIInfra/microservices-connector/README.html#prerequisites">Prerequisites</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../GenAIInfra/microservices-connector/README.html#introduction">Introduction</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../GenAIInfra/microservices-connector/README.html#to-deploy-on-the-cluster">To Deploy on the cluster</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../GenAIInfra/microservices-connector/README.html#next-step">Next Step</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../GenAIInfra/microservices-connector/README.html#to-uninstall">To Uninstall</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../../GenAIInfra/microservices-connector/usage_guide.html">Usage guide for genai-microservices-connector(GMC)</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../../GenAIInfra/microservices-connector/usage_guide.html#use-gmc-to-compose-a-chatqna-pipeline">Use GMC to compose a chatQnA Pipeline</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../GenAIInfra/microservices-connector/usage_guide.html#use-gmc-to-adjust-the-chatqna-pipeline">Use GMC to adjust the chatQnA Pipeline</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../../GenAIInfra/scripts/README.html">Scripts and tools</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../GenAIInfra/helm-charts/chatqna/README.html">ChatQnA</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../../GenAIInfra/helm-charts/chatqna/README.html#installing-the-chart">Installing the Chart</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../GenAIInfra/helm-charts/chatqna/README.html#values">Values</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../../GenAIInfra/helm-charts/codegen/README.html">CodeGen</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../../GenAIInfra/helm-charts/codegen/README.html#installing-the-chart">Installing the Chart</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../GenAIInfra/helm-charts/codegen/README.html#values">Values</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../../GenAIInfra/manifests/ChatQnA/README.html">Prebuilt images</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../GenAIInfra/manifests/ChatQnA/README.html#deploy-services-with-xeon">Deploy Services with Xeon</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../../GenAIInfra/manifests/ChatQnA/README.html#deploy">Deploy</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../GenAIInfra/manifests/ChatQnA/README.html#undeploy">Undeploy</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../../GenAIInfra/manifests/ChatQnA/README.html#deploy-services-with-gaudi">Deploy Services with Gaudi</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../../GenAIInfra/manifests/ChatQnA/README.html#id1">Deploy</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../GenAIInfra/manifests/ChatQnA/README.html#id2">Undeploy</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../../GenAIInfra/manifests/ChatQnA/README.html#verify-services">Verify Services</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../GenAIInfra/manifests/CodeTrans/README.html">Deploy On Xeon</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../GenAIInfra/manifests/CodeTrans/README.html#deploy-on-gaudi">Deploy On Gaudi</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../GenAIInfra/manifests/CodeTrans/README.html#verify-llm-services">Verify llm Services</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../GenAIInfra/manifests/CodeTrans/README.html#generate-the-llm-file-from-helm-chart">Generate the llm file from helm chart</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../GenAIInfra/manifests/DocSum/README.html">Deploy On Xeon</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../GenAIInfra/manifests/DocSum/README.html#deploy-on-gaudi">Deploy On Gaudi</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../GenAIInfra/manifests/DocSum/README.html#verify-llm-services">Verify llm Services</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../GenAIInfra/manifests/DocSum/README.html#generate-the-llm-file-from-helm-chart">Generate the llm file from helm chart</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../GenAIInfra/helm-charts/common/data-prep/README.html">data-prep</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../../GenAIInfra/helm-charts/common/data-prep/README.html#installing-the-chart">Installing the Chart</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../GenAIInfra/helm-charts/common/data-prep/README.html#values">Values</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../../GenAIInfra/helm-charts/common/embedding-usvc/README.html">embedding-usvc</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../../GenAIInfra/helm-charts/common/embedding-usvc/README.html#installing-the-chart">Installing the Chart</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../GenAIInfra/helm-charts/common/embedding-usvc/README.html#values">Values</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../../GenAIInfra/helm-charts/common/llm-uservice/README.html">llm-uservice</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../../GenAIInfra/helm-charts/common/llm-uservice/README.html#installing-the-chart">Installing the Chart</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../GenAIInfra/helm-charts/common/llm-uservice/README.html#values">Values</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../../GenAIInfra/helm-charts/common/redis-vector-db/README.html">tei</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../../GenAIInfra/helm-charts/common/redis-vector-db/README.html#installing-the-chart">Installing the Chart</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../GenAIInfra/helm-charts/common/redis-vector-db/README.html#values">Values</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../../GenAIInfra/helm-charts/common/reranking-usvc/README.html">reranking-usvc</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../../GenAIInfra/helm-charts/common/reranking-usvc/README.html#installing-the-chart">Installing the Chart</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../GenAIInfra/helm-charts/common/reranking-usvc/README.html#values">Values</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../../GenAIInfra/helm-charts/common/retriever-usvc/README.html">retriever-usvc</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../../GenAIInfra/helm-charts/common/retriever-usvc/README.html#installing-the-chart">Installing the Chart</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../GenAIInfra/helm-charts/common/retriever-usvc/README.html#values">Values</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../../GenAIInfra/helm-charts/common/tei/README.html">tei</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../../GenAIInfra/helm-charts/common/tei/README.html#installing-the-chart">Installing the Chart</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../GenAIInfra/helm-charts/common/tei/README.html#values">Values</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../../GenAIInfra/helm-charts/common/teirerank/README.html">teirerank</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../../GenAIInfra/helm-charts/common/teirerank/README.html#installing-the-chart">Installing the Chart</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../GenAIInfra/helm-charts/common/teirerank/README.html#values">Values</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../../GenAIInfra/helm-charts/common/tgi/README.html">tgi</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../../GenAIInfra/helm-charts/common/tgi/README.html#installing-the-chart">Installing the Chart</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../GenAIInfra/helm-charts/common/tgi/README.html#values">Values</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../../GenAIInfra/manifests/CodeGen/gaudi/README.html">Deploy Services</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../GenAIInfra/manifests/CodeGen/gaudi/README.html#verify-services">Verify Services</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../GenAIInfra/manifests/CodeGen/xeon/README.html">Deploy Services</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../GenAIInfra/manifests/CodeGen/xeon/README.html#verify-services">Verify Services</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../../../Governance.html">Project Governance</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../../Governance/Technical%20Steering%20Committee%20%28TSC%29%20Gives%20%26%20Gets.html">Technical Steering Committee (TSC) Gives &amp; Gets</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../../Governance/Technical%20Steering%20Committee%20%28TSC%29%20Gives%20%26%20Gets.html#tsc-member-gives">TSC Member Gives</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../Governance/Technical%20Steering%20Committee%20%28TSC%29%20Gives%20%26%20Gets.html#tsc-member-gets">TSC Member Gets</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../../Governance/charter.html">Technical Charter (the “Charter”) for OPEA a Series of LF Projects, LLC</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../../Governance/charter.html#mission-and-scope-of-the-project">1. Mission and Scope of the Project</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../Governance/charter.html#technical-steering-committee">2. Technical Steering Committee</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../Governance/charter.html#tsc-voting">3. TSC Voting</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../Governance/charter.html#compliance-with-policies">4. Compliance with Policies</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../Governance/charter.html#community-assets">5. Community Assets</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../Governance/charter.html#general-rules-and-operations">6. General Rules and Operations.</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../Governance/charter.html#intellectual-property-policy">7. Intellectual Property Policy</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../Governance/charter.html#amendments">8. Amendments</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../../../genindex.html">Index</a></li>
</ul>


        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../../../index.html">OPEA™</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
  <!-- Latest -->
  
  

  <li><a href="../../../../index.html">Latest</a> &raquo;</li>
  
  <li>Build MegaService of CodeGen on Gaudi</li>

      <li class="wy-breadcrumbs-aside">
            <a href="../../../../_sources/GenAIExamples/CodeGen/docker/gaudi/README.md.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
  
    <!-- div class="admonition important">
        <p class="admonition-title">Important</p>
        <p>This is the latest documentation for the development branch of
        the OPEA Project (main).<br/>Use the drop-down menu on the left to select
        documentation for a stable release.</p>
    </div -->
  
  
           <div itemprop="articleBody">
             
  <section id="build-megaservice-of-codegen-on-gaudi">
<h1>Build MegaService of CodeGen on Gaudi<a class="headerlink" href="#build-megaservice-of-codegen-on-gaudi" title="Link to this heading">¶</a></h1>
<p>This document outlines the deployment process for a CodeGen application utilizing the <a class="reference external" href="https://github.com/opea-project/GenAIComps.git">GenAIComps</a> microservice pipeline on Intel Gaudi2 server. The steps include Docker images creation, container deployment via Docker Compose, and service execution to integrate microservices such as <code class="docutils literal notranslate"><span class="pre">llm</span></code>. We will publish the Docker images to the Docker Hub soon, further simplifying the deployment process for this service.</p>
<section id="build-docker-images">
<h2>🚀 Build Docker Images<a class="headerlink" href="#build-docker-images" title="Link to this heading">¶</a></h2>
<p>First of all, you need to build the Docker images locally. This step can be ignored after the Docker images published to the Docker Hub.</p>
<section id="git-clone-genaicomps">
<h3>1. Git Clone GenAIComps<a class="headerlink" href="#git-clone-genaicomps" title="Link to this heading">¶</a></h3>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>git<span class="w"> </span>clone<span class="w"> </span>https://github.com/opea-project/GenAIComps.git
<span class="nb">cd</span><span class="w"> </span>GenAIComps
</pre></div>
</div>
</section>
<section id="build-the-llm-docker-image">
<h3>2. Build the LLM Docker Image<a class="headerlink" href="#build-the-llm-docker-image" title="Link to this heading">¶</a></h3>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>docker<span class="w"> </span>build<span class="w"> </span>-t<span class="w"> </span>opea/llm-tgi:latest<span class="w"> </span>--build-arg<span class="w"> </span><span class="nv">https_proxy</span><span class="o">=</span><span class="nv">$https_proxy</span><span class="w"> </span>--build-arg<span class="w"> </span><span class="nv">http_proxy</span><span class="o">=</span><span class="nv">$http_proxy</span><span class="w"> </span>-f<span class="w"> </span>comps/llms/text-generation/tgi/Dockerfile<span class="w"> </span>.
</pre></div>
</div>
</section>
<section id="build-the-megaservice-docker-image">
<h3>3. Build the MegaService Docker Image<a class="headerlink" href="#build-the-megaservice-docker-image" title="Link to this heading">¶</a></h3>
<p>To construct the Mega Service, we utilize the <a class="reference external" href="https://github.com/opea-project/GenAIComps.git">GenAIComps</a> microservice pipeline within the <code class="docutils literal notranslate"><span class="pre">codegen.py</span></code> Python script. Build the MegaService Docker image via the command below:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>git<span class="w"> </span>clone<span class="w"> </span>https://github.com/opea-project/GenAIExamples
<span class="nb">cd</span><span class="w"> </span>GenAIExamples/CodeGen/docker
docker<span class="w"> </span>build<span class="w"> </span>-t<span class="w"> </span>opea/codegen:latest<span class="w"> </span>--build-arg<span class="w"> </span><span class="nv">https_proxy</span><span class="o">=</span><span class="nv">$https_proxy</span><span class="w"> </span>--build-arg<span class="w"> </span><span class="nv">http_proxy</span><span class="o">=</span><span class="nv">$http_proxy</span><span class="w"> </span>-f<span class="w"> </span>Dockerfile<span class="w"> </span>.
</pre></div>
</div>
</section>
<section id="build-the-ui-docker-image">
<h3>4. Build the UI Docker Image<a class="headerlink" href="#build-the-ui-docker-image" title="Link to this heading">¶</a></h3>
<p>Construct the frontend Docker image via the command below:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="nb">cd</span><span class="w"> </span>GenAIExamples/CodeGen/docker/ui/
docker<span class="w"> </span>build<span class="w"> </span>-t<span class="w"> </span>opea/codegen-ui:latest<span class="w"> </span>--build-arg<span class="w"> </span><span class="nv">https_proxy</span><span class="o">=</span><span class="nv">$https_proxy</span><span class="w"> </span>--build-arg<span class="w"> </span><span class="nv">http_proxy</span><span class="o">=</span><span class="nv">$http_proxy</span><span class="w"> </span>-f<span class="w"> </span>./docker/Dockerfile<span class="w"> </span>.
</pre></div>
</div>
<p>Then run the command <code class="docutils literal notranslate"><span class="pre">docker</span> <span class="pre">images</span></code>, you will have the following 3 Docker images:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">opea/llm-tgi:latest</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">opea/codegen:latest</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">opea/codegen-ui:latest</span></code></p></li>
</ul>
</section>
</section>
<section id="start-microservices-and-megaservice">
<h2>🚀 Start MicroServices and MegaService<a class="headerlink" href="#start-microservices-and-megaservice" title="Link to this heading">¶</a></h2>
<p>The CodeGen megaservice manages a single microservice called LLM within a Directed Acyclic Graph (DAG). In the diagram above, the LLM microservice is a language model microservice that generates code snippets based on the user’s input query. The TGI service serves as a text generation interface, providing a RESTful API for the LLM microservice. The CodeGen Gateway acts as the entry point for the CodeGen application, invoking the Megaservice to generate code snippets in response to the user’s input query.</p>
<p>The mega flow of the CodeGen application, from user’s input query to the application’s output response, is as follows:</p>
<div class="highlight-mermaid notranslate"><div class="highlight"><pre><span></span>flowchart LR
    subgraph CodeGen
        direction LR
        A[User] --&gt; |Input query| B[CodeGen Gateway]
        B --&gt; |Invoke| Megaservice
        subgraph Megaservice[&quot;Megaservice&quot;]
            direction TB
            C((LLM&lt;br&gt;9000)) -. Post .-&gt; D{{TGI Service&lt;br&gt;8028}}
        end
        Megaservice --&gt; |Output| E[Response]
    end

    subgraph Legend
        direction LR
        G([Microservice]) ==&gt; H([Microservice])
        I([Microservice]) -.-&gt; J{{Server API}}
    end
</pre></div>
</div>
<section id="setup-environment-variables">
<h3>Setup Environment Variables<a class="headerlink" href="#setup-environment-variables" title="Link to this heading">¶</a></h3>
<p>Since the <code class="docutils literal notranslate"><span class="pre">docker_compose.yaml</span></code> will consume some environment variables, you need to setup them in advance as below.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="nb">export</span><span class="w"> </span><span class="nv">no_proxy</span><span class="o">=</span><span class="si">${</span><span class="nv">your_no_proxy</span><span class="si">}</span>
<span class="nb">export</span><span class="w"> </span><span class="nv">http_proxy</span><span class="o">=</span><span class="si">${</span><span class="nv">your_http_proxy</span><span class="si">}</span>
<span class="nb">export</span><span class="w"> </span><span class="nv">https_proxy</span><span class="o">=</span><span class="si">${</span><span class="nv">your_http_proxy</span><span class="si">}</span>
<span class="nb">export</span><span class="w"> </span><span class="nv">LLM_MODEL_ID</span><span class="o">=</span><span class="s2">&quot;meta-llama/CodeLlama-7b-hf&quot;</span>
<span class="nb">export</span><span class="w"> </span><span class="nv">TGI_LLM_ENDPOINT</span><span class="o">=</span><span class="s2">&quot;http://</span><span class="si">${</span><span class="nv">host_ip</span><span class="si">}</span><span class="s2">:8028&quot;</span>
<span class="nb">export</span><span class="w"> </span><span class="nv">HUGGINGFACEHUB_API_TOKEN</span><span class="o">=</span><span class="si">${</span><span class="nv">your_hf_api_token</span><span class="si">}</span>
<span class="nb">export</span><span class="w"> </span><span class="nv">MEGA_SERVICE_HOST_IP</span><span class="o">=</span><span class="si">${</span><span class="nv">host_ip</span><span class="si">}</span>
<span class="nb">export</span><span class="w"> </span><span class="nv">LLM_SERVICE_HOST_IP</span><span class="o">=</span><span class="si">${</span><span class="nv">host_ip</span><span class="si">}</span>
<span class="nb">export</span><span class="w"> </span><span class="nv">BACKEND_SERVICE_ENDPOINT</span><span class="o">=</span><span class="s2">&quot;http://</span><span class="si">${</span><span class="nv">host_ip</span><span class="si">}</span><span class="s2">:7778/v1/codegen&quot;</span>
</pre></div>
</div>
<blockquote>
<div><p>[!NOTE]
Please replace the <code class="docutils literal notranslate"><span class="pre">host_ip</span></code> with you external IP address, do not use <code class="docutils literal notranslate"><span class="pre">localhost</span></code>.</p>
</div></blockquote>
</section>
<section id="start-the-docker-containers-for-all-services">
<h3>Start the Docker Containers for All Services<a class="headerlink" href="#start-the-docker-containers-for-all-services" title="Link to this heading">¶</a></h3>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="nb">cd</span><span class="w"> </span>GenAIExamples/CodeGen/docker/gaudi
docker<span class="w"> </span>compose<span class="w"> </span>-f<span class="w"> </span>docker_compose.yaml<span class="w"> </span>up<span class="w"> </span>-d
</pre></div>
</div>
</section>
<section id="validate-the-microservices-and-megaservice">
<h3>Validate the MicroServices and MegaService<a class="headerlink" href="#validate-the-microservices-and-megaservice" title="Link to this heading">¶</a></h3>
<ol class="arabic simple">
<li><p>TGI Service</p></li>
</ol>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>curl<span class="w"> </span>http://<span class="si">${</span><span class="nv">host_ip</span><span class="si">}</span>:8028/generate<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>-X<span class="w"> </span>POST<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>-d<span class="w"> </span><span class="s1">&#39;{&quot;inputs&quot;:&quot;Implement a high-level API for a TODO list application. The API takes as input an operation request and updates the TODO list in place. If the request is invalid, raise an exception.&quot;,&quot;parameters&quot;:{&quot;max_new_tokens&quot;:256, &quot;do_sample&quot;: true}}&#39;</span><span class="w"> </span><span class="se">\</span>
<span class="w">  </span>-H<span class="w"> </span><span class="s1">&#39;Content-Type: application/json&#39;</span>
</pre></div>
</div>
<ol class="arabic simple" start="2">
<li><p>LLM Microservices</p></li>
</ol>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>curl<span class="w"> </span>http://<span class="si">${</span><span class="nv">host_ip</span><span class="si">}</span>:9000/v1/chat/completions<span class="se">\</span>
<span class="w">  </span>-X<span class="w"> </span>POST<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>-d<span class="w"> </span><span class="s1">&#39;{&quot;query&quot;:&quot;Implement a high-level API for a TODO list application. The API takes as input an operation request and updates the TODO list in place. If the request is invalid, raise an exception.&quot;,&quot;max_new_tokens&quot;:256,&quot;top_k&quot;:10,&quot;top_p&quot;:0.95,&quot;typical_p&quot;:0.95,&quot;temperature&quot;:0.01,&quot;repetition_penalty&quot;:1.03,&quot;streaming&quot;:true}&#39;</span><span class="w"> </span><span class="se">\</span>
<span class="w">  </span>-H<span class="w"> </span><span class="s1">&#39;Content-Type: application/json&#39;</span>
</pre></div>
</div>
<ol class="arabic simple" start="3">
<li><p>MegaService</p></li>
</ol>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>curl<span class="w"> </span>http://<span class="si">${</span><span class="nv">host_ip</span><span class="si">}</span>:7778/v1/codegen<span class="w"> </span>-H<span class="w"> </span><span class="s2">&quot;Content-Type: application/json&quot;</span><span class="w"> </span>-d<span class="w"> </span><span class="s1">&#39;{</span>
<span class="s1">     &quot;messages&quot;: &quot;Implement a high-level API for a TODO list application. The API takes as input an operation request and updates the TODO list in place. If the request is invalid, raise an exception.&quot;</span>
<span class="s1">     }&#39;</span>
</pre></div>
</div>
</section>
</section>
<section id="enable-langsmith-to-monitor-application-optional">
<h2>Enable LangSmith to Monitor Application (Optional)<a class="headerlink" href="#enable-langsmith-to-monitor-application-optional" title="Link to this heading">¶</a></h2>
<p>LangSmith offers tools to debug, evaluate, and monitor language models and intelligent agents. It can be used to assess benchmark data for each microservice. Before launching your services with <code class="docutils literal notranslate"><span class="pre">docker</span> <span class="pre">compose</span> <span class="pre">-f</span> <span class="pre">docker_compose.yaml</span> <span class="pre">up</span> <span class="pre">-d</span></code>, you need to enable LangSmith tracing by setting the <code class="docutils literal notranslate"><span class="pre">LANGCHAIN_TRACING_V2</span></code> environment variable to true and configuring your LangChain API key.</p>
<p>Here’s how you can do it:</p>
<ol class="arabic simple">
<li><p>Install the latest version of LangSmith:</p></li>
</ol>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>pip<span class="w"> </span>install<span class="w"> </span>-U<span class="w"> </span>langsmith
</pre></div>
</div>
<ol class="arabic simple" start="2">
<li><p>Set the necessary environment variables:</p></li>
</ol>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="nb">export</span><span class="w"> </span><span class="nv">LANGCHAIN_TRACING_V2</span><span class="o">=</span><span class="nb">true</span>
<span class="nb">export</span><span class="w"> </span><span class="nv">LANGCHAIN_API_KEY</span><span class="o">=</span>ls_...
</pre></div>
</div>
</section>
<section id="launch-the-ui">
<h2>🚀 Launch the UI<a class="headerlink" href="#launch-the-ui" title="Link to this heading">¶</a></h2>
<p>To access the frontend, open the following URL in your browser: <code class="docutils literal notranslate"><span class="pre">http://{host_ip}:5173</span></code>. By default, the UI runs on port 5173 internally. If you prefer to use a different host port to access the frontend, you can modify the port mapping in the <code class="docutils literal notranslate"><span class="pre">docker_compose.yaml</span></code> file as shown below:</p>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="w">  </span><span class="nt">codegen-xeon-ui-server</span><span class="p">:</span>
<span class="w">    </span><span class="nt">image</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">opea/codegen-ui:latest</span>
<span class="w">    </span><span class="l l-Scalar l-Scalar-Plain">...</span>
<span class="w">    </span><span class="nt">ports</span><span class="p">:</span>
<span class="w">      </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="s">&quot;80:5173&quot;</span>
</pre></div>
</div>
<p><img alt="project-screenshot" src="../../../../_images/codeGen_ui_init.jpg" /></p>
</section>
<section id="install-copilot-vscode-extension-from-plugin-marketplace-as-the-frontend">
<h2>Install Copilot VSCode extension from Plugin Marketplace as the frontend<a class="headerlink" href="#install-copilot-vscode-extension-from-plugin-marketplace-as-the-frontend" title="Link to this heading">¶</a></h2>
<p>In addition to the Svelte UI, users can also install the Copilot VSCode extension from the Plugin Marketplace as the frontend.</p>
<p>Install <code class="docutils literal notranslate"><span class="pre">Neural</span> <span class="pre">Copilot</span></code> in VSCode as below.</p>
<p><img alt="Install-screenshot" src="../../../../_images/codegen_copilot.png" /></p>
<section id="how-to-use">
<h3>How to Use<a class="headerlink" href="#how-to-use" title="Link to this heading">¶</a></h3>
<section id="service-url-setting">
<h4>Service URL Setting<a class="headerlink" href="#service-url-setting" title="Link to this heading">¶</a></h4>
<p>Please adjust the service URL in the extension settings based on the endpoint of the CodeGen backend service.</p>
<p><img alt="Setting-screenshot" src="../../../../_images/codegen_settings.png" />
<img alt="Setting-screenshot" src="../../../../_images/codegen_endpoint.png" /></p>
</section>
<section id="customize">
<h4>Customize<a class="headerlink" href="#customize" title="Link to this heading">¶</a></h4>
<p>The Copilot enables users to input their corresponding sensitive information and tokens in the user settings according to their own needs. This customization enhances the accuracy and output content to better meet individual requirements.</p>
<p><img alt="Customize" src="../../../../_images/codegen_customize.png" /></p>
</section>
<section id="code-suggestion">
<h4>Code Suggestion<a class="headerlink" href="#code-suggestion" title="Link to this heading">¶</a></h4>
<p>To trigger inline completion, you’ll need to type <code class="docutils literal notranslate"><span class="pre">#</span> <span class="pre">{your</span> <span class="pre">keyword}</span> <span class="pre">(start</span> <span class="pre">with</span> <span class="pre">your</span> <span class="pre">programming</span> <span class="pre">language's</span> <span class="pre">comment</span> <span class="pre">keyword,</span> <span class="pre">like</span> <span class="pre">//</span> <span class="pre">in</span> <span class="pre">C++</span> <span class="pre">and</span> <span class="pre">#</span> <span class="pre">in</span> <span class="pre">python)</span></code>. Make sure the <code class="docutils literal notranslate"><span class="pre">Inline</span> <span class="pre">Suggest</span></code> is enabled from the VS Code Settings.
For example:</p>
<p><img alt="code suggestion" src="../../../../_images/codegen_suggestion.png" /></p>
<p>To provide programmers with a smooth experience, the Copilot supports multiple ways to trigger inline code suggestions. If you are interested in the details, they are summarized as follows:</p>
<ul class="simple">
<li><p>Generate code from single-line comments: The simplest way introduced before.</p></li>
<li><p>Generate code from consecutive single-line comments:</p></li>
</ul>
<p><img alt="codegen from single-line comments" src="../../../../_images/codegen_single_line.png" /></p>
<ul class="simple">
<li><p>Generate code from multi-line comments, which will not be triggered until there is at least one <code class="docutils literal notranslate"><span class="pre">space</span></code> outside the multi-line comment):</p></li>
</ul>
<p><img alt="codegen from multi-line comments" src="../../../../_images/codegen_multi_line.png" /></p>
<ul class="simple">
<li><p>Automatically complete multi-line comments:</p></li>
</ul>
<p><img alt="auto complete" src="../../../../_images/codegen_auto_complete.jpg" /></p>
</section>
</section>
<section id="chat-with-ai-assistant">
<h3>Chat with AI assistant<a class="headerlink" href="#chat-with-ai-assistant" title="Link to this heading">¶</a></h3>
<p>You can start a conversation with the AI programming assistant by clicking on the robot icon in the plugin bar on the left:</p>
<p><img alt="icon" src="../../../../_images/codegen_icon.png" /></p>
<p>Then you can see the conversation window on the left, where you can chat with the AI assistant:</p>
<p><img alt="dialog" src="../../../../_images/codegen_dialog.png" /></p>
<p>There are 4 areas worth noting as shown in the screenshot above:</p>
<ol class="arabic simple">
<li><p>Enter and submit your question</p></li>
<li><p>Your previous questions</p></li>
<li><p>Answers from AI assistant (Code will be highlighted properly according to the programming language it is written in, also support streaming output)</p></li>
<li><p>Copy or replace code with one click (Note that you need to select the code in the editor first and then click “replace”, otherwise the code will be inserted)</p></li>
</ol>
<p>You can also select the code in the editor and ask the AI assistant questions about the code directly.
For example:</p>
<ul class="simple">
<li><p>Select code</p></li>
</ul>
<p><img alt="select code" src="../../../../_images/codegen_select_code.png" /></p>
<ul class="simple">
<li><p>Ask question and get answer</p></li>
</ul>
<p><img alt="qna" src="../../../../_images/codegen_qna.png" /></p>
</section>
</section>
</section>


           </div>
          </div>

          <footer>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2024-2024 OPEA™, a Series of LF Projects, LLC.

<!-- span class="lastupdated">Last updated on Jul 15, 2024. Published on </span -->
<span class="lastupdated">Published on Jul 15, 2024.</span>

  </div>

   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>